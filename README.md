# awesome-llm-utilities

Tooling and frameworks to support building tools that utilize LLM agents

# Agent orchestration, multi-step planning

* https://github.com/hwchase17/langchain - ‚ö° Building applications with LLMs through composability ‚ö°
* https://github.com/jerryjliu/llama_index - LlamaIndex (GPT Index) is a project that provides a central interface to connect your LLM's with external data.
* https://github.com/stanfordnlp/dsp - ùóóùó¶ùó£: Demonstrate-Search-Predict. A framework for composing retrieval and language models for knowledge-intensive NLP.
* https://github.com/amazon-science/mm-cot - Multimodal Chain-of-Thought Reasoning in Language Models

# Coding agents

* https://github.com/irgolic/AutoPR - Fix issues with AI-generated pull requests, powered by ChatGPT. discord.gg/ykk7Znt3K6
* https://github.com/e2b-dev/e2b - e2b (english2bits) is an IDE powered by AI agents. Developers describe what they want to build by writing documentation. Then let AI agents with access to tools do the coding work. e2b.dev
* https://github.com/dmarx/the-rest-of-the-fucking-owl - Trigger an LLM in your CI/CD to auto-complete your work

# Prompt Construction, Generation Validation and Guidance

* https://github.com/ShreyaR/guardrails - Adding guardrails to large language models. discord.gg/Jsey3mX98B
* https://github.com/benlipkin/probsem - a framework to leverage large language models (LLMs) to assign context-conditional probability distributions over queried strings, with default support for all OpenAI engines and HuggingFace CausalLM models.


# IDE extensions, frontends, browser plugins

* https://github.com/MateusZitelli/PromptMate - 

# Annotation, misc

* https://github.com/explosion/prodigy-openai-recipes - This repository contains example code on how to combine zero- and few-shot learning with a small annotation effort to obtain a high-quality dataset with maximum efficiency. Specifically, we use large language models available from OpenAI to provide us with an initial set of predictions, then spin up a Prodigy instance on our local machine to go through these predictions and curate them. This allows us to obtain a gold-standard dataset pretty quickly, and train a smaller, supervised model that fits our exact needs and use-case.
* https://github.com/hwchase17/chat-langchain - This repo is an implementation of a locally hosted chatbot specifically focused on question answering over the LangChain documentation. 
* https://github.com/whitead/paper-qa - LLM Chain for answering questions from documents with citations

# Speech hooks

* https://github.com/NVIDIA/NeMo - NVIDIA NeMo is a conversational AI toolkit built for researchers working on automatic speech recognition (ASR), text-to-speech synthesis (TTS), large language models (LLMs), and natural language processing (NLP). The primary objective of NeMo is to help researchers from industry and academia to reuse prior work (code and pretrained models) and make it easier to create new conversational AI models.
